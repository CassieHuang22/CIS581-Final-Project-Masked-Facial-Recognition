{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7d7efff74dd4f02bdcd8a7dcee3cf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b96156c4d1143408e9ebacc3efd7fa1",
              "IPY_MODEL_8ac2549a8ae94860a8398c230d9de86e",
              "IPY_MODEL_1a9ab908934049e5a9c343efcd558523"
            ],
            "layout": "IPY_MODEL_7e00cbcf33854f40a710448c78bce0e8"
          }
        },
        "4b96156c4d1143408e9ebacc3efd7fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235c5636de7d44458eb06f339ec0af98",
            "placeholder": "​",
            "style": "IPY_MODEL_2853ed518fdc4e3088e6518a4cf1a0ab",
            "value": "100%"
          }
        },
        "8ac2549a8ae94860a8398c230d9de86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2ed34ffb5b4e7f92ba38ea9a7afdcf",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89b6824a7d1548f1a283164669fc53c2",
            "value": 111898327
          }
        },
        "1a9ab908934049e5a9c343efcd558523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810d55cad97e435ea43296eec8073af9",
            "placeholder": "​",
            "style": "IPY_MODEL_8b8f2f4995084f81a32d86f626fdf7c8",
            "value": " 107M/107M [00:16&lt;00:00, 6.54MB/s]"
          }
        },
        "7e00cbcf33854f40a710448c78bce0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235c5636de7d44458eb06f339ec0af98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2853ed518fdc4e3088e6518a4cf1a0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef2ed34ffb5b4e7f92ba38ea9a7afdcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b6824a7d1548f1a283164669fc53c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "810d55cad97e435ea43296eec8073af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8f2f4995084f81a32d86f626fdf7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CassieHuang22/CIS581-Final-Project-Masked-Facial-Recognition/blob/main/facial_recognition_masked.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training on Masked Faces\n",
        "\n",
        "This notebook trains our model for our dataset of masked faces and creates graphs of our training results."
      ],
      "metadata": {
        "id": "FSPpcShBP6sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wXchm5gKXab",
        "outputId": "5b39fc2b-d078-45ad-e488-a53a6b5ade4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/CIS5810/Final Project/Model Weights Masked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5G2l4reK-Td",
        "outputId": "f4129be8-56ce-4081-861f-810c7d03cb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CIS5810/Final Project/Model Weights Masked\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqih8xVnzJS2",
        "outputId": "b6b387ee-efbe-4891-cefa-5defe9360d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (7.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (0.14.0+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->facenet-pytorch) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->facenet-pytorch) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->facenet-pytorch) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->facenet-pytorch) (2022.9.24)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet-pytorch) (4.4.0)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet-pytorch) (1.13.0+cu116)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3hNjWgzGqM_"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "sX6vGY8CrVC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from torchvision.datasets.utils import check_integrity, download_and_extract_archive, download_url, verify_str_arg\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "hnhfsqRkzNeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Masked Dataset\n",
        "\n",
        "Due to modifying the original LFW dataset, we have to create our own custom dataset. We modified the original LFW code by changing the _change_integrity function."
      ],
      "metadata": {
        "id": "zz_wKnudRTRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _LFW(VisionDataset):\n",
        "\n",
        "    base_folder = \"lfw-py\"\n",
        "    download_url_prefix = \"http://vis-www.cs.umass.edu/lfw/\"\n",
        "\n",
        "    file_dict = {\n",
        "        \"original\": (\"lfw\", \"lfw.tgz\", \"a17d05bd522c52d84eca14327a23d494\"),\n",
        "        \"funneled\": (\"lfw_funneled\", \"lfw-funneled.tgz\", \"1b42dfed7d15c9b2dd63d5e5840c86ad\"),\n",
        "        \"deepfunneled\": (\"lfw-deepfunneled\", \"lfw-deepfunneled.tgz\", \"68331da3eb755a505a502b5aacb3c201\"),\n",
        "    }\n",
        "    checksums = {\n",
        "        \"pairs.txt\": \"9f1ba174e4e1c508ff7cdf10ac338a7d\",\n",
        "        \"pairsDevTest.txt\": \"5132f7440eb68cf58910c8a45a2ac10b\",\n",
        "        \"pairsDevTrain.txt\": \"4f27cbf15b2da4a85c1907eb4181ad21\",\n",
        "        \"people.txt\": \"450f0863dd89e85e73936a6d71a3474b\",\n",
        "        \"peopleDevTest.txt\": \"e4bf5be0a43b5dcd9dc5ccfcb8fb19c5\",\n",
        "        \"peopleDevTrain.txt\": \"54eaac34beb6d042ed3a7d883e247a21\",\n",
        "        \"lfw-names.txt\": \"a6d0a479bd074669f656265a6e693f6d\",\n",
        "    }\n",
        "    annot_file = {\"10fold\": \"\", \"train\": \"DevTrain\", \"test\": \"DevTest\"}\n",
        "    names = \"lfw-names.txt\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        split: str,\n",
        "        image_set: str,\n",
        "        view: str,\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "        download: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__(os.path.join(root, self.base_folder), transform=transform, target_transform=target_transform)\n",
        "\n",
        "        self.image_set = verify_str_arg(image_set.lower(), \"image_set\", self.file_dict.keys())\n",
        "        images_dir, self.filename, self.md5 = self.file_dict[self.image_set]\n",
        "\n",
        "        self.view = verify_str_arg(view.lower(), \"view\", [\"people\", \"pairs\"])\n",
        "        self.split = verify_str_arg(split.lower(), \"split\", [\"10fold\", \"train\", \"test\"])\n",
        "        self.labels_file = f\"{self.view}{self.annot_file[self.split]}.txt\"\n",
        "        self.data: List[Any] = []\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        #if not self._check_integrity():\n",
        "        #    raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n",
        "\n",
        "        self.images_dir = os.path.join(self.root, images_dir)\n",
        "\n",
        "    def _loader(self, path: str) -> Image.Image:\n",
        "        with open(path, \"rb\") as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert(\"RGB\")\n",
        "\n",
        "    def _check_integrity(self) -> bool:\n",
        "        st1 = check_integrity(os.path.join(self.root, self.filename), self.md5)\n",
        "        st2 = check_integrity(os.path.join(self.root, self.labels_file), self.checksums[self.labels_file])\n",
        "        if not st1 or not st2:\n",
        "            return False\n",
        "        if self.view == \"people\":\n",
        "            return check_integrity(os.path.join(self.root, self.names), self.checksums[self.names])\n",
        "        return True\n",
        "\n",
        "    def download(self) -> None:\n",
        "        if self._check_integrity():\n",
        "            print(\"Files already downloaded and verified\")\n",
        "            return\n",
        "        url = f\"{self.download_url_prefix}{self.filename}\"\n",
        "        download_and_extract_archive(url, self.root, filename=self.filename, md5=self.md5)\n",
        "        download_url(f\"{self.download_url_prefix}{self.labels_file}\", self.root)\n",
        "        if self.view == \"people\":\n",
        "            download_url(f\"{self.download_url_prefix}{self.names}\", self.root)\n",
        "\n",
        "    def _get_path(self, identity: str, no: Union[int, str]) -> str:\n",
        "        return os.path.join(self.images_dir, identity, f\"{identity}_{int(no):04d}.jpg\")\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"Alignment: {self.image_set}\\nSplit: {self.split}\"\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "XWUlngzOzu2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "cache_present = list(np.load('./cache_present.npy'))\n",
        "cache_absent = list(np.load('./cache_absent.npy'))"
      ],
      "metadata": {
        "id": "8__wWcDr8y1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_exists(path):\n",
        "  if path in cache_present:\n",
        "    return True\n",
        "  elif path in cache_absent:\n",
        "    return False\n",
        "  else:\n",
        "    if os.path.isfile(path):\n",
        "      cache_present.append(path)\n",
        "      return True\n",
        "    else:\n",
        "      cache_absent.append(path)\n",
        "      return False"
      ],
      "metadata": {
        "id": "JRzQ4y9n8zn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"The following code saves our file lists so they can be loaded later and help train our model faster.\"\"\"\n",
        "import numpy as np\n",
        "cache_present_np = np.array(cache_present)\n",
        "cache_absent_np = np.array(cache_absent)\n",
        "np.save('./cache_present', cache_present_np)\n",
        "np.save('./cache_absent', cache_present_np)"
      ],
      "metadata": {
        "id": "D5V55EdFK9Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LFWPairs(_LFW):\n",
        "    \"\"\"`LFW <http://vis-www.cs.umass.edu/lfw/>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where directory\n",
        "            ``lfw-py`` exists or will be saved to if download is set to True.\n",
        "        split (string, optional): The image split to use. Can be one of ``train``, ``test``,\n",
        "            ``10fold``. Defaults to ``10fold``.\n",
        "        image_set (str, optional): Type of image funneling to use, ``original``, ``funneled`` or\n",
        "            ``deepfunneled``. Defaults to ``funneled``.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomRotation``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        split: str = \"10fold\",\n",
        "        image_set: str = \"funneled\",\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "        download: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__(root, split, image_set, \"pairs\", transform, target_transform, download)\n",
        "\n",
        "        self.pair_names, self.data, self.targets = self._get_pairs(self.images_dir)\n",
        "\n",
        "    def _get_pairs(self, images_dir: str) -> Tuple[List[Tuple[str, str]], List[Tuple[str, str]], List[int]]:\n",
        "        pair_names, data, targets = [], [], []\n",
        "        with open(os.path.join(self.root, self.labels_file)) as f:\n",
        "            lines = f.readlines()\n",
        "            if self.split == \"10fold\":\n",
        "                n_folds, n_pairs = lines[0].split(\"\\t\")\n",
        "                n_folds, n_pairs = int(n_folds), int(n_pairs)\n",
        "            else:\n",
        "                n_folds, n_pairs = 1, int(lines[0])\n",
        "            s = 1\n",
        "\n",
        "            for fold in range(n_folds):\n",
        "                matched_pairs = [line.strip().split(\"\\t\") for line in lines[s : s + n_pairs]]\n",
        "                unmatched_pairs = [line.strip().split(\"\\t\") for line in lines[s + n_pairs : s + (2 * n_pairs)]]\n",
        "                s += 2 * n_pairs\n",
        "                for pair in matched_pairs:\n",
        "                    img1, img2, same = self._get_path(pair[0], pair[1]), self._get_path(pair[0], pair[2]), 1\n",
        "                    pair_names.append((pair[0], pair[0]))\n",
        "                    if file_exists(img1) and file_exists(img2):\n",
        "                      data.append((img1, img2))\n",
        "                      targets.append(same)\n",
        "                for pair in unmatched_pairs:\n",
        "                    img1, img2, same = self._get_path(pair[0], pair[1]), self._get_path(pair[2], pair[3]), 0\n",
        "                    pair_names.append((pair[0], pair[2]))\n",
        "                    if file_exists(img1) and file_exists(img2):\n",
        "                      data.append((img1, img2))\n",
        "                      targets.append(same)\n",
        "                    \n",
        "\n",
        "        return pair_names, data, targets\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any, int]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image1, image2, target) where target is `0` for different indentities and `1` for same identities.\n",
        "        \"\"\"\n",
        "        img1, img2 = self.data[index]\n",
        "        img1, img2 = self._loader(img1), self._loader(img2)\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img1, img2 = self.transform(img1), self.transform(img2)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img1, img2, target\n"
      ],
      "metadata": {
        "id": "q2hsDa-jz1L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([transforms.Resize((160, 160)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
        "test_transforms = transforms.Compose([transforms.Resize((160, 160)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) "
      ],
      "metadata": {
        "id": "FPKum62yvQ1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_examples(self, n=10, test_dataset=False):\n",
        "        \"\"\"\n",
        "        Returns `n` random images form dataset. If `test_dataset` parameter\n",
        "        is not provided or False it will return images from training part of dataset.\n",
        "        If `test_dataset` parameter is True it will return images from testing part of dataset.\n",
        "        \"\"\"\n",
        "        if test_dataset:\n",
        "            data_path = self.test_data_path\n",
        "        else:\n",
        "            data_path = self.train_data_path\n",
        "\n",
        "        images = os.listdir(os.path.join(data_path, 'inputs'))\n",
        "        images = random.sample(images, n)\n",
        "        inputs = [os.path.join(data_path, 'inputs', img) for img in images]\n",
        "        outputs = [os.path.join(data_path, 'outputs', img) for img in images]\n",
        "        return inputs, outputs"
      ],
      "metadata": {
        "id": "KUDD79fPQJm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfw_train = LFWPairs(\".\", split='train', transform=train_transforms)"
      ],
      "metadata": {
        "id": "I663sR_hGvqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfw_test = LFWPairs(\".\", split='test', transform=test_transforms)"
      ],
      "metadata": {
        "id": "X6SFjIX6-622"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Dk_zOYnISM07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import InceptionResnetV1"
      ],
      "metadata": {
        "id": "5Gnee9Vdyizn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class face_rec(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #self.resnet_18 = torchvision.models.resnet18()\n",
        "    self.inception_resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "    self.fc_layers = torch.nn.Sequential(torch.nn.Linear(512, 1), torch.nn.Sigmoid())\n",
        "\n",
        "  def forward(self, img1, img2):\n",
        "    encoding_1 = self.inception_resnet(img1)\n",
        "    encoding_2 = self.inception_resnet(img2)\n",
        "    input_fc = torch.abs(encoding_1 - encoding_2)\n",
        "    out = self.fc_layers(input_fc)\n",
        "    return out"
      ],
      "metadata": {
        "id": "PkTP1CbaG9tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(lfw_train, batch_size=16,\n",
        "                                          shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(lfw_test, batch_size=16)"
      ],
      "metadata": {
        "id": "sTQZXIcRuxkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(lfw_train)\n",
        "val_N = len(lfw_test)"
      ],
      "metadata": {
        "id": "OKN66RYv-ueB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "weight_decay = 1e-2"
      ],
      "metadata": {
        "id": "C25m-njoLeLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(face_model, criterion, optimizer, trainloader, testloader, epochs):\n",
        "  train_losses = []\n",
        "  validation_losses = []\n",
        "  validation_errors = []\n",
        "  epochs_list = []\n",
        "  net = face_model.to(device)\n",
        "  best_val_accuracy = 0\n",
        "  # Freeze model inception_resnet parameters\n",
        "  for param in net.inception_resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "  for epoch in range(epochs):\n",
        "    epoch_loss = 0.0\n",
        "    flag = 0\n",
        "    if epoch == 20 and flag == 0:\n",
        "      for op_params in optimizer.param_groups:\n",
        "        op_params['lr'] = 1e-3\n",
        "      flag = 1\n",
        "    net.train()\n",
        "    for i, (img1, img2, labels) in enumerate(trainloader):\n",
        "      images1 = img1.to(device)\n",
        "      images2 = img2.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = net(images1, images2)\n",
        "      loss = criterion(torch.flatten(outputs), labels.float())\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      epoch_loss += loss.item() * images1.shape[0]\n",
        "      optimizer.step()\n",
        "      #if ((i+1) % 20 == 0):\n",
        "      #  print(\"Epoch: \" + str(epoch + 1) + \", Step: \" + str(i+1) + \", Loss = \" + str(loss.item()))\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      val_loss = 0\n",
        "      for test_img1, test_img2, labels in testloader:\n",
        "        test_images1 = test_img1.to(device)\n",
        "        test_images2 = test_img2.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(test_images1, test_images2)\n",
        "        val_loss += criterion(torch.flatten(outputs), labels.float()).item() * test_images1.shape[0]\n",
        "        predictions = torch.flatten(torch.tensor(outputs.clone().detach() > 0.5, dtype=int))\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    val_accuracy = correct / total\n",
        "    train_losses.append(epoch_loss / N)\n",
        "    validation_losses.append(val_loss / val_N)\n",
        "    validation_errors.append(1 - val_accuracy)\n",
        "    epochs_list.append(epoch)\n",
        "    if(((epoch + 1) > epochs // 3) and (val_accuracy > best_val_accuracy)):\n",
        "      best_val_accuracy = val_accuracy\n",
        "      file_name = \"MASKED_weights_lr\"+str(lr)+\"_wd\"+str(weight_decay)+\"_epoch\"+str(epochs)\n",
        "      torch.save(net.state_dict(), file_name)\n",
        "    print(\"Epoch: \" + str(epoch + 1) + \", Epoch-loss: \" + str(epoch_loss / N) + \", Accuracy-test: \" + str(val_accuracy))\n",
        "  \n",
        "  return train_losses, validation_losses, validation_errors, epochs_list"
      ],
      "metadata": {
        "id": "HHU10RgAuRRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facenet = face_rec()\n",
        "optimizer = torch.optim.Adam(facenet.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "Qam1Bnfktulp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b7d7efff74dd4f02bdcd8a7dcee3cf6b",
            "4b96156c4d1143408e9ebacc3efd7fa1",
            "8ac2549a8ae94860a8398c230d9de86e",
            "1a9ab908934049e5a9c343efcd558523",
            "7e00cbcf33854f40a710448c78bce0e8",
            "235c5636de7d44458eb06f339ec0af98",
            "2853ed518fdc4e3088e6518a4cf1a0ab",
            "ef2ed34ffb5b4e7f92ba38ea9a7afdcf",
            "89b6824a7d1548f1a283164669fc53c2",
            "810d55cad97e435ea43296eec8073af9",
            "8b8f2f4995084f81a32d86f626fdf7c8"
          ]
        },
        "outputId": "63f81722-8fdc-44c4-ee15-ac18d54d7645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7d7efff74dd4f02bdcd8a7dcee3cf6b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, validation_losses, validation_errors, epochs_list = train_model(facenet, criterion, optimizer, trainloader, testloader, 20)"
      ],
      "metadata": {
        "id": "r0m99B3ht4Aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "9158011b-d572-48e0-f558-b6467c5f82dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-97c17d259700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-e63771456117>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(face_model, criterion, optimizer, trainloader, testloader, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mimages1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mimages2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8cda163d0925>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m         \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8e25bf433f5c>\u001b[0m in \u001b[0;36m_loader\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "ggzOjOyyTAgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = face_rec().to(device)\n",
        "best_model.load_state_dict(torch.load(\"/content/drive/MyDrive/CIS5810/Final Project/Model Weights Masked/MASKED_weights_lr0.001_wd0.01_epoch20\"))\n",
        "best_model.eval()"
      ],
      "metadata": {
        "id": "pNSExBv0-oPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a41daf-50a8-4ee3-a842-9569cd248d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "face_rec(\n",
              "  (inception_resnet): InceptionResnetV1(\n",
              "    (conv2d_1a): BasicConv2d(\n",
              "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2d_2a): BasicConv2d(\n",
              "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2d_2b): BasicConv2d(\n",
              "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (conv2d_3b): BasicConv2d(\n",
              "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2d_4a): BasicConv2d(\n",
              "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2d_4b): BasicConv2d(\n",
              "      (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (repeat_1): Sequential(\n",
              "      (0): Block35(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (branch2): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): Block35(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (branch2): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): Block35(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (branch2): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (3): Block35(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (branch2): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (4): Block35(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (branch2): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (mixed_6a): Mixed_6a(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (repeat_2): Sequential(\n",
              "      (0): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (3): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (4): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (5): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (6): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (7): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (8): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (9): Block17(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (mixed_7a): Mixed_7a(\n",
              "      (branch0): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (repeat_3): Sequential(\n",
              "      (0): Block8(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): Block8(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): Block8(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (3): Block8(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (4): Block8(\n",
              "        (branch0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (branch1): Sequential(\n",
              "          (0): BasicConv2d(\n",
              "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (1): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "          (2): BasicConv2d(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU()\n",
              "          )\n",
              "        )\n",
              "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (block8): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "    (dropout): Dropout(p=0.6, inplace=False)\n",
              "    (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "    (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(net):\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      val_loss = 0\n",
        "      for test_img1, test_img2, labels in testloader:\n",
        "        test_images1 = test_img1.to(device)\n",
        "        test_images2 = test_img2.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(test_images1, test_images2)\n",
        "        val_loss += criterion(torch.flatten(outputs), labels.float()).item() * test_images1.shape[0]\n",
        "        predictions = torch.flatten(torch.tensor(outputs.clone().detach() > 0.5, dtype=int))\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "  return correct / total"
      ],
      "metadata": {
        "id": "EhwPb3cCG8Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best accuracy:\", evaluate_model(best_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlkF7-9gG_A3",
        "outputId": "91d3678b-b60f-4874-e52b-47b5b64cee2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-e3aef4b4a0d5>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predictions = torch.flatten(torch.tensor(outputs.clone().detach() > 0.5, dtype=int))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy: 0.8199195171026157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Plots\n",
        "The code below creates plots of our results for training."
      ],
      "metadata": {
        "id": "ixYxUi5DSWLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 20})\n",
        "\n",
        "losses = [0.6911138793244896,\n",
        "0.6880981432176945,\n",
        "0.6859944732082555,\n",
        "0.6848479186185993, \n",
        "0.6823498958154118, \n",
        "0.681148484369861, \n",
        "0.6791600811146217,\n",
        "0.67881919519865, \n",
        "0.6773789730584253,\n",
        "0.6744122678588315,\n",
        "0.6752931060412888,\n",
        "0.6739502938841279,\n",
        "0.6743421871412619, \n",
        "0.6712695394259216, \n",
        "0.6713780253754612, \n",
        "0.6701562615131221, \n",
        "0.6695251382128222, \n",
        "0.6687141039119772, \n",
        "0.6680673688663872, \n",
        "0.6666260593604689]\n",
        "epochs = list(range(1, 21))\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.scatter(epochs, losses, color='red')\n",
        "plt.plot(epochs, losses, color='red')\n",
        "plt.xticks(range(1, 21))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss Value\")\n",
        "plt.title(\"Loss vs. Training Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "accuracy = [0.5,\n",
        "0.5,\n",
        "0.5412474849094567,\n",
        "0.7665995975855131,\n",
        "0.7223340040241448,\n",
        "0.6408450704225352,\n",
        "0.5845070422535211,\n",
        " 0.7676056338028169,\n",
        "0.6680080482897385,\n",
        "0.607645875251509,\n",
        "0.6901408450704225,\n",
        "0.7183098591549296,\n",
        "0.7132796780684104,\n",
        "0.6448692152917505,\n",
        "0.7816901408450704,\n",
        "0.8199195171026157,\n",
        "0.8158953722334004,\n",
        "0.7746478873239436,\n",
        "0.6297786720321932,\n",
        "0.7907444668008048]\n",
        "epochs = list(range(1, 21))\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.scatter(epochs, 1-np.array(accuracy), color='purple')\n",
        "plt.plot(epochs, 1-np.array(accuracy), color='purple')\n",
        "plt.xticks(range(1, 21))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Test Error\")\n",
        "plt.title(\"Test Error vs. Training Epochs\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n9TQcmqE-4ss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}